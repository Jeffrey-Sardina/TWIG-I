['run_exp.py', '0', 'DBpedia50', '20', '5e-5', 'zscore', '256', '64', '100', '0', '1', 'simple', '1']
Creating a new model from scratch
loading NN
done loading NN
loading dataset
DBpedia50
X_p: torch.Size([32203, 23])
X_p: torch.Size([2095, 23])
X_p: torch.Size([123, 23])
done loading dataset
loading filters
done loading filters
loading negative samplers
loading triple features from cache
done loading negative samplers
Running in hyperparameter evaluation mode
TWIG will be evaulaited on the validation set
and will not be tested each epoch on the validation set
running training and eval
TWIG_KGL_v0(
  (linear_struct_1): Linear(in_features=22, out_features=10, bias=True)
  (relu_1): ReLU()
  (dropout_1): Dropout(p=0.01, inplace=False)
  (linear_struct_2): Linear(in_features=10, out_features=10, bias=True)
  (relu_2): ReLU()
  (dropout_2): Dropout(p=0.01, inplace=False)
  (linear_final): Linear(in_features=10, out_features=1, bias=True)
  (sigmoid_final): Sigmoid()
)
REC: Training with epochs = 20
Epoch 1 -- batch 0 / 126 loss: 0.10923340916633606
Epoch 2 -- batch 0 / 126 loss: 0.10115205496549606
Epoch 3 -- batch 0 / 126 loss: 0.09057044982910156
Epoch 4 -- batch 0 / 126 loss: 0.07959205657243729
Epoch 5 -- batch 0 / 126 loss: 0.07210522890090942
Saving checkpoint at epoch 5; prefix = chkpt-ID_6259443329992969
Epoch 6 -- batch 0 / 126 loss: 0.06520814448595047
Epoch 7 -- batch 0 / 126 loss: 0.058241814374923706
Epoch 8 -- batch 0 / 126 loss: 0.050314247608184814
Epoch 9 -- batch 0 / 126 loss: 0.04313031584024429
Epoch 10 -- batch 0 / 126 loss: 0.03490183874964714
Saving checkpoint at epoch 10; prefix = chkpt-ID_6259443329992969
Epoch 11 -- batch 0 / 126 loss: 0.028620434924960136
Epoch 12 -- batch 0 / 126 loss: 0.02293536067008972
Epoch 13 -- batch 0 / 126 loss: 0.017722956836223602
Epoch 14 -- batch 0 / 126 loss: 0.013849728740751743
Epoch 15 -- batch 0 / 126 loss: 0.011229765601456165
Saving checkpoint at epoch 15; prefix = chkpt-ID_6259443329992969
Epoch 16 -- batch 0 / 126 loss: 0.008475636132061481
Epoch 17 -- batch 0 / 126 loss: 0.00652311323210597
Epoch 18 -- batch 0 / 126 loss: 0.005163705907762051
Epoch 19 -- batch 0 / 126 loss: 0.004365225322544575
Epoch 20 -- batch 0 / 126 loss: 0.003311061765998602
Saving checkpoint at epoch 20; prefix = chkpt-ID_6259443329992969
Done Training!

==================================
Testing (cite this): dataloader for dataset DBpedia50
Testing (cite this): batch 0 / 2
Testing (cite this): batch 1 / 2
total number of ranks, torch.Size([123])
====== Ranks ======
ranks size: torch.Size([123])
test_loss: 0.1428925171494484
mr: 16681.853515625
mrr: 0.12659354507923126
h1: 0.09756097197532654
h3: 0.1463414579629898
h5: 0.15447154641151428
h10: 0.15447154641151428
==================================

Done Testing!
done with training and eval
Experiments took 465 seconds on 
