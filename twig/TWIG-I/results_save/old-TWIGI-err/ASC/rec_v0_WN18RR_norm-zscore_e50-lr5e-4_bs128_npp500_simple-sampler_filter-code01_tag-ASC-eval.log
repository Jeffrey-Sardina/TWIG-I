['run_exp.py', '0', 'WN18RR', '50', '5e-4', 'zscore', '128', '64', '500', '0', '1', 'simple', '0']
Creating a new model from scratch
loading NN
done loading NN
loading dataset
WN18RR
X_p: torch.Size([86835, 23])
X_p: torch.Size([2924, 23])
X_p: torch.Size([2824, 23])
done loading dataset
loading filters
done loading filters
loading negative samplers
loading triple features from cache
done loading negative samplers
running training and eval
TWIG_KGL_v0(
  (linear_struct_1): Linear(in_features=22, out_features=10, bias=True)
  (relu_1): ReLU()
  (dropout_1): Dropout(p=0.01, inplace=False)
  (linear_struct_2): Linear(in_features=10, out_features=10, bias=True)
  (relu_2): ReLU()
  (dropout_2): Dropout(p=0.01, inplace=False)
  (linear_final): Linear(in_features=10, out_features=1, bias=True)
  (sigmoid_final): Sigmoid()
)
REC: Training with epochs = 50
Epoch 1 -- batch 0 / 679 loss: 0.14663441479206085
batch 500 / 679 loss: 0.0003092031693086028
Epoch 2 -- batch 0 / 679 loss: 3.785071021411568e-05
batch 500 / 679 loss: 0.0001668722543399781
Epoch 3 -- batch 0 / 679 loss: 2.4086468329187483e-05
batch 500 / 679 loss: 0.000134889836772345
Epoch 4 -- batch 0 / 679 loss: 2.0998171748942696e-05
batch 500 / 679 loss: 0.00012137644807808101
Epoch 5 -- batch 0 / 679 loss: 2.0877685528830625e-05
batch 500 / 679 loss: 0.00010906923125730827
Saving checkpoint at epoch 5; prefix = chkpt-ID_7040994098753909
Epoch 6 -- batch 0 / 679 loss: 1.8164433640777133e-05
batch 500 / 679 loss: 0.00010075692262034863
Epoch 7 -- batch 0 / 679 loss: 1.1519458894326817e-05
batch 500 / 679 loss: 7.918672781670466e-05
Epoch 8 -- batch 0 / 679 loss: 1.7922071492648683e-05
batch 500 / 679 loss: 5.6230765039799735e-05
Epoch 9 -- batch 0 / 679 loss: 1.9009867173735984e-05
batch 500 / 679 loss: 2.7667376343742944e-05
Epoch 10 -- batch 0 / 679 loss: 2.130416214640718e-05
batch 500 / 679 loss: 1.8747015928965993e-05
Saving checkpoint at epoch 10; prefix = chkpt-ID_7040994098753909
Epoch 11 -- batch 0 / 679 loss: 5.951869752607308e-06
batch 500 / 679 loss: 1.8496908523957245e-05
Epoch 12 -- batch 0 / 679 loss: 1.542784957564436e-05
batch 500 / 679 loss: 2.335428143851459e-05
Epoch 13 -- batch 0 / 679 loss: 4.019770585728111e-06
batch 500 / 679 loss: 9.050229891727213e-06
Epoch 14 -- batch 0 / 679 loss: 8.753010661166627e-06
batch 500 / 679 loss: 1.4887916222505737e-05
Epoch 15 -- batch 0 / 679 loss: 1.1639486729109194e-05
batch 500 / 679 loss: 1.8150938558392227e-05
Saving checkpoint at epoch 15; prefix = chkpt-ID_7040994098753909
Epoch 16 -- batch 0 / 679 loss: 3.60652325070987e-06
batch 500 / 679 loss: 1.3921271602157503e-05
Epoch 17 -- batch 0 / 679 loss: 5.006006631447235e-06
batch 500 / 679 loss: 7.306959105335409e-06
Epoch 18 -- batch 0 / 679 loss: 3.922168161807349e-06
batch 500 / 679 loss: 5.968011464574374e-06
Epoch 19 -- batch 0 / 679 loss: 2.6453903956280556e-06
batch 500 / 679 loss: 6.3921379478415474e-06
Epoch 20 -- batch 0 / 679 loss: 4.755796453537187e-06
batch 500 / 679 loss: 8.619092113804072e-06
Saving checkpoint at epoch 20; prefix = chkpt-ID_7040994098753909
Epoch 21 -- batch 0 / 679 loss: 1.331130647486134e-06
batch 500 / 679 loss: 1.8825767256203108e-05
Epoch 22 -- batch 0 / 679 loss: 0.0
batch 500 / 679 loss: 1.112852078222204e-05
Epoch 23 -- batch 0 / 679 loss: 3.3794703995226882e-06
batch 500 / 679 loss: 4.3924305259679386e-07
Epoch 24 -- batch 0 / 679 loss: 6.953544925636379e-06
batch 500 / 679 loss: 1.2225425052747596e-05
Epoch 25 -- batch 0 / 679 loss: 4.152537712798221e-06
batch 500 / 679 loss: 1.5828805771889165e-05
Saving checkpoint at epoch 25; prefix = chkpt-ID_7040994098753909
Epoch 26 -- batch 0 / 679 loss: 0.0
batch 500 / 679 loss: 5.420581601356389e-06
Epoch 27 -- batch 0 / 679 loss: 4.014247224404244e-06
batch 500 / 679 loss: 4.606743459589779e-06
Epoch 28 -- batch 0 / 679 loss: 6.335296802717494e-06
batch 500 / 679 loss: 1.0175172974413726e-05
Epoch 29 -- batch 0 / 679 loss: 2.9402540349110495e-06
batch 500 / 679 loss: 1.1972371794399805e-05
Epoch 30 -- batch 0 / 679 loss: 1.6074690165623906e-06
batch 500 / 679 loss: 3.9388319237332325e-06
Saving checkpoint at epoch 30; prefix = chkpt-ID_7040994098753909
Epoch 31 -- batch 0 / 679 loss: 0.0
batch 500 / 679 loss: 7.2022094173007645e-06
Epoch 32 -- batch 0 / 679 loss: 3.0231312848627567e-06
batch 500 / 679 loss: 1.1326302228553686e-05
Epoch 33 -- batch 0 / 679 loss: 2.123791546182474e-06
batch 500 / 679 loss: 1.7820886569097638e-05
Epoch 34 -- batch 0 / 679 loss: 9.366063750348985e-06
batch 500 / 679 loss: 7.315733000723412e-06
Epoch 35 -- batch 0 / 679 loss: 4.070306204084773e-06
batch 500 / 679 loss: 1.6714941011741757e-05
Saving checkpoint at epoch 35; prefix = chkpt-ID_7040994098753909
Epoch 36 -- batch 0 / 679 loss: 3.0225481850720826e-07
batch 500 / 679 loss: 9.49022523855092e-06
Epoch 37 -- batch 0 / 679 loss: 1.0821570413099835e-06
batch 500 / 679 loss: 1.642853021621704e-05
Epoch 38 -- batch 0 / 679 loss: 0.0
batch 500 / 679 loss: 2.392052010691259e-06
Epoch 39 -- batch 0 / 679 loss: 0.0
batch 500 / 679 loss: 7.956119588925503e-06
Epoch 40 -- batch 0 / 679 loss: 5.013970167055959e-06
batch 500 / 679 loss: 6.70620192977367e-06
Saving checkpoint at epoch 40; prefix = chkpt-ID_7040994098753909
Epoch 41 -- batch 0 / 679 loss: 5.49981359654339e-06
batch 500 / 679 loss: 5.212397809373215e-06
Epoch 42 -- batch 0 / 679 loss: 0.0
batch 500 / 679 loss: 5.49805520222435e-07
Epoch 43 -- batch 0 / 679 loss: 1.5625000742147677e-06
batch 500 / 679 loss: 9.492134267929941e-06
Epoch 44 -- batch 0 / 679 loss: 2.9638201795023633e-06
batch 500 / 679 loss: 7.076600468280958e-06
Epoch 45 -- batch 0 / 679 loss: 7.91564798419131e-06
batch 500 / 679 loss: 5.847355168953072e-06
Saving checkpoint at epoch 45; prefix = chkpt-ID_7040994098753909
Epoch 46 -- batch 0 / 679 loss: 4.941091447108192e-06
batch 500 / 679 loss: 8.038738087634556e-06
Epoch 47 -- batch 0 / 679 loss: 4.777356480190065e-06
batch 500 / 679 loss: 5.719816272176104e-06
Epoch 48 -- batch 0 / 679 loss: 6.325687081698561e-06
batch 500 / 679 loss: 5.485096608026652e-06
Epoch 49 -- batch 0 / 679 loss: 8.368470503228309e-07
batch 500 / 679 loss: 1.5070177141751628e-05
Epoch 50 -- batch 0 / 679 loss: 0.0
batch 500 / 679 loss: 1.4069340068090241e-05
Saving checkpoint at epoch 50; prefix = chkpt-ID_7040994098753909
Done Training!

==================================
Testing (cite this): dataloader for dataset WN18RR
Testing (cite this): batch 0 / 46
Testing (cite this): batch 1 / 46
Testing (cite this): batch 2 / 46
Testing (cite this): batch 3 / 46
Testing (cite this): batch 4 / 46
Testing (cite this): batch 5 / 46
Testing (cite this): batch 6 / 46
Testing (cite this): batch 7 / 46
Testing (cite this): batch 8 / 46
Testing (cite this): batch 9 / 46
Testing (cite this): batch 10 / 46
Testing (cite this): batch 11 / 46
Testing (cite this): batch 12 / 46
Testing (cite this): batch 13 / 46
Testing (cite this): batch 14 / 46
Testing (cite this): batch 15 / 46
Testing (cite this): batch 16 / 46
Testing (cite this): batch 17 / 46
Testing (cite this): batch 18 / 46
Testing (cite this): batch 19 / 46
Testing (cite this): batch 20 / 46
Testing (cite this): batch 21 / 46
Testing (cite this): batch 22 / 46
Testing (cite this): batch 23 / 46
Testing (cite this): batch 24 / 46
Testing (cite this): batch 25 / 46
Testing (cite this): batch 26 / 46
Testing (cite this): batch 27 / 46
Testing (cite this): batch 28 / 46
Testing (cite this): batch 29 / 46
Testing (cite this): batch 30 / 46
Testing (cite this): batch 31 / 46
Testing (cite this): batch 32 / 46
Testing (cite this): batch 33 / 46
Testing (cite this): batch 34 / 46
Testing (cite this): batch 35 / 46
Testing (cite this): batch 36 / 46
Testing (cite this): batch 37 / 46
Testing (cite this): batch 38 / 46
Testing (cite this): batch 39 / 46
Testing (cite this): batch 40 / 46
Testing (cite this): batch 41 / 46
Testing (cite this): batch 42 / 46
Testing (cite this): batch 43 / 46
Testing (cite this): batch 44 / 46
Testing (cite this): batch 45 / 46
ranks: tensor([48345., 62070., 39497.,  ..., 62174., 45837.,   230.])
mr: 41555.36328125
mrr: 0.06786919385194778
h1: 0.059507522732019424
h3: 0.06566347181797028
h5: 0.07934336364269257
h10: 0.09370724856853485
==================================

Done Testing!
done with training and eval
Experiments took 9963 seconds on 
