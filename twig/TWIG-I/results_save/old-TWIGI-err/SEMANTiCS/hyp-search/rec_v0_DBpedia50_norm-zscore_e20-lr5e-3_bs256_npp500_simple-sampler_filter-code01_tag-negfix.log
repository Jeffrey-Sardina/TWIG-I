['run_exp.py', '0', 'DBpedia50', '20', '5e-3', 'zscore', '256', '64', '500', '0', '1', 'simple', '1']
Creating a new model from scratch
loading NN
done loading NN
loading dataset
DBpedia50
X_p: torch.Size([32203, 23])
X_p: torch.Size([2095, 23])
X_p: torch.Size([123, 23])
done loading dataset
loading filters
done loading filters
loading negative samplers
loading triple features from cache
done loading negative samplers
Running in hyperparameter evaluation mode
TWIG will be evaulaited on the validation set
and will not be tested each epoch on the validation set
running training and eval
TWIG_KGL_v0(
  (linear_struct_1): Linear(in_features=22, out_features=10, bias=True)
  (relu_1): ReLU()
  (dropout_1): Dropout(p=0.01, inplace=False)
  (linear_struct_2): Linear(in_features=10, out_features=10, bias=True)
  (relu_2): ReLU()
  (dropout_2): Dropout(p=0.01, inplace=False)
  (linear_final): Linear(in_features=10, out_features=1, bias=True)
  (sigmoid_final): Sigmoid()
)
REC: Training with epochs = 20
Epoch 1 -- batch 0 / 126 loss: 0.10922474414110184
Epoch 2 -- batch 0 / 126 loss: 5.564174352912232e-05
Epoch 3 -- batch 0 / 126 loss: 6.028397910995409e-05
Epoch 4 -- batch 0 / 126 loss: 5.291571142151952e-05
Epoch 5 -- batch 0 / 126 loss: 3.202800508006476e-05
Saving checkpoint at epoch 5; prefix = chkpt-ID_8979075129815801
Epoch 6 -- batch 0 / 126 loss: 2.7712248993339017e-05
Epoch 7 -- batch 0 / 126 loss: 2.5612969693611376e-05
Epoch 8 -- batch 0 / 126 loss: 1.7000787920551375e-05
Epoch 9 -- batch 0 / 126 loss: 2.7927580958930776e-05
Epoch 10 -- batch 0 / 126 loss: 2.0474881239351816e-05
Saving checkpoint at epoch 10; prefix = chkpt-ID_8979075129815801
Epoch 11 -- batch 0 / 126 loss: 2.0994257283746265e-05
Epoch 12 -- batch 0 / 126 loss: 1.8053053281619214e-05
Epoch 13 -- batch 0 / 126 loss: 1.2713842806988396e-05
Epoch 14 -- batch 0 / 126 loss: 2.3723227059235796e-05
Epoch 15 -- batch 0 / 126 loss: 3.274989649071358e-05
Saving checkpoint at epoch 15; prefix = chkpt-ID_8979075129815801
Epoch 16 -- batch 0 / 126 loss: 1.4894857486069668e-05
Epoch 17 -- batch 0 / 126 loss: 1.721468652249314e-05
Epoch 18 -- batch 0 / 126 loss: 2.046939880528953e-05
Epoch 19 -- batch 0 / 126 loss: 2.4615885195089504e-05
Epoch 20 -- batch 0 / 126 loss: 1.545735176478047e-05
Saving checkpoint at epoch 20; prefix = chkpt-ID_8979075129815801
Done Training!

==================================
Testing (cite this): dataloader for dataset DBpedia50
Testing (cite this): batch 0 / 2
Testing (cite this): batch 1 / 2
total number of ranks, torch.Size([123])
====== Ranks ======
ranks size: torch.Size([123])
test_loss: 0.11755917221307755
mr: 13692.447265625
mrr: 0.2613312602043152
h1: 0.2195121943950653
h3: 0.2926829159259796
h5: 0.31707316637039185
h10: 0.34959349036216736
==================================

Done Testing!
done with training and eval
Experiments took 1391 seconds on 
