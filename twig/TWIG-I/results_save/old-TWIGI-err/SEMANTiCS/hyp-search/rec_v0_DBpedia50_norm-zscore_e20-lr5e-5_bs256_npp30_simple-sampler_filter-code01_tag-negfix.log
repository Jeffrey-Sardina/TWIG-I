['run_exp.py', '0', 'DBpedia50', '20', '5e-5', 'zscore', '256', '64', '30', '0', '1', 'simple', '1']
Creating a new model from scratch
loading NN
done loading NN
loading dataset
DBpedia50
X_p: torch.Size([32203, 23])
X_p: torch.Size([2095, 23])
X_p: torch.Size([123, 23])
done loading dataset
loading filters
done loading filters
loading negative samplers
loading triple features from cache
done loading negative samplers
Running in hyperparameter evaluation mode
TWIG will be evaulaited on the validation set
and will not be tested each epoch on the validation set
running training and eval
TWIG_KGL_v0(
  (linear_struct_1): Linear(in_features=22, out_features=10, bias=True)
  (relu_1): ReLU()
  (dropout_1): Dropout(p=0.01, inplace=False)
  (linear_struct_2): Linear(in_features=10, out_features=10, bias=True)
  (relu_2): ReLU()
  (dropout_2): Dropout(p=0.01, inplace=False)
  (linear_final): Linear(in_features=10, out_features=1, bias=True)
  (sigmoid_final): Sigmoid()
)
REC: Training with epochs = 20
Epoch 1 -- batch 0 / 126 loss: 0.10936332494020462
Epoch 2 -- batch 0 / 126 loss: 0.10091236978769302
Epoch 3 -- batch 0 / 126 loss: 0.0907183438539505
Epoch 4 -- batch 0 / 126 loss: 0.0797090083360672
Epoch 5 -- batch 0 / 126 loss: 0.07188215851783752
Saving checkpoint at epoch 5; prefix = chkpt-ID_6584640980344206
Epoch 6 -- batch 0 / 126 loss: 0.06508037447929382
Epoch 7 -- batch 0 / 126 loss: 0.05811489745974541
Epoch 8 -- batch 0 / 126 loss: 0.04991863667964935
Epoch 9 -- batch 0 / 126 loss: 0.04261237382888794
Epoch 10 -- batch 0 / 126 loss: 0.03524176403880119
Saving checkpoint at epoch 10; prefix = chkpt-ID_6584640980344206
Epoch 11 -- batch 0 / 126 loss: 0.028270551934838295
Epoch 12 -- batch 0 / 126 loss: 0.02254538983106613
Epoch 13 -- batch 0 / 126 loss: 0.017685120925307274
Epoch 14 -- batch 0 / 126 loss: 0.01403701864182949
Epoch 15 -- batch 0 / 126 loss: 0.011304067447781563
Saving checkpoint at epoch 15; prefix = chkpt-ID_6584640980344206
Epoch 16 -- batch 0 / 126 loss: 0.008354388177394867
Epoch 17 -- batch 0 / 126 loss: 0.006632849108427763
Epoch 18 -- batch 0 / 126 loss: 0.005118835251778364
Epoch 19 -- batch 0 / 126 loss: 0.0044647338800132275
Epoch 20 -- batch 0 / 126 loss: 0.00320916878990829
Saving checkpoint at epoch 20; prefix = chkpt-ID_6584640980344206
Done Training!

==================================
Testing (cite this): dataloader for dataset DBpedia50
Testing (cite this): batch 0 / 2
Testing (cite this): batch 1 / 2
total number of ranks, torch.Size([123])
====== Ranks ======
ranks size: torch.Size([123])
test_loss: 0.14297079294919968
mr: 16701.162109375
mrr: 0.12375127524137497
h1: 0.09756097197532654
h3: 0.1463414579629898
h5: 0.15447154641151428
h10: 0.15447154641151428
==================================

Done Testing!
done with training and eval
Experiments took 275 seconds on 
