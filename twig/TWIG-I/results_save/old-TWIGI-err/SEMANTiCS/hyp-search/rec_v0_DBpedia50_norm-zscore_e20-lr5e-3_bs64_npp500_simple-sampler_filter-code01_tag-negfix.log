['run_exp.py', '0', 'DBpedia50', '20', '5e-3', 'zscore', '64', '64', '500', '0', '1', 'simple', '1']
Creating a new model from scratch
loading NN
done loading NN
loading dataset
DBpedia50
X_p: torch.Size([32203, 23])
X_p: torch.Size([2095, 23])
X_p: torch.Size([123, 23])
done loading dataset
loading filters
done loading filters
loading negative samplers
loading triple features from cache
done loading negative samplers
Running in hyperparameter evaluation mode
TWIG will be evaulaited on the validation set
and will not be tested each epoch on the validation set
running training and eval
TWIG_KGL_v0(
  (linear_struct_1): Linear(in_features=22, out_features=10, bias=True)
  (relu_1): ReLU()
  (dropout_1): Dropout(p=0.01, inplace=False)
  (linear_struct_2): Linear(in_features=10, out_features=10, bias=True)
  (relu_2): ReLU()
  (dropout_2): Dropout(p=0.01, inplace=False)
  (linear_final): Linear(in_features=10, out_features=1, bias=True)
  (sigmoid_final): Sigmoid()
)
REC: Training with epochs = 20
Epoch 1 -- batch 0 / 504 loss: 0.1117090955376625
batch 500 / 504 loss: 0.00011948703468078747
Epoch 2 -- batch 0 / 504 loss: 4.910293500870466e-05
batch 500 / 504 loss: 0.00010889464465435594
Epoch 3 -- batch 0 / 504 loss: 2.890195173677057e-05
batch 500 / 504 loss: 0.00011659993469947949
Epoch 4 -- batch 0 / 504 loss: 1.6408996089012362e-05
batch 500 / 504 loss: 6.792393833165988e-05
Epoch 5 -- batch 0 / 504 loss: 1.592753324075602e-05
batch 500 / 504 loss: 9.494035475654528e-05
Saving checkpoint at epoch 5; prefix = chkpt-ID_160571361360402
Epoch 6 -- batch 0 / 504 loss: 3.0422463169088587e-05
batch 500 / 504 loss: 3.708858275786042e-05
Epoch 7 -- batch 0 / 504 loss: 3.605413076002151e-05
batch 500 / 504 loss: 3.9251073758350685e-05
Epoch 8 -- batch 0 / 504 loss: 2.4835726435412653e-05
batch 500 / 504 loss: 1.1801529581134673e-05
Epoch 9 -- batch 0 / 504 loss: 1.0593446859274991e-05
batch 500 / 504 loss: 3.0482271540677175e-05
Epoch 10 -- batch 0 / 504 loss: 1.187104862765409e-05
batch 500 / 504 loss: 2.0020741430926137e-05
Saving checkpoint at epoch 10; prefix = chkpt-ID_160571361360402
Epoch 11 -- batch 0 / 504 loss: 7.637186172360089e-06
batch 500 / 504 loss: 7.242818537633866e-05
Epoch 12 -- batch 0 / 504 loss: 3.9654802094446495e-05
batch 500 / 504 loss: 1.738760511216242e-05
Epoch 13 -- batch 0 / 504 loss: 1.2356512343103532e-05
batch 500 / 504 loss: 1.4798761185375042e-05
Epoch 14 -- batch 0 / 504 loss: 1.9709246771526523e-05
batch 500 / 504 loss: 1.4803087651671376e-05
Epoch 15 -- batch 0 / 504 loss: 1.3656843293574639e-05
batch 500 / 504 loss: 2.4689683414180763e-05
Saving checkpoint at epoch 15; prefix = chkpt-ID_160571361360402
Epoch 16 -- batch 0 / 504 loss: 1.3054016562819015e-05
batch 500 / 504 loss: 2.8964468583581038e-05
Epoch 17 -- batch 0 / 504 loss: 2.4959870643215254e-05
batch 500 / 504 loss: 4.296693987271283e-06
Epoch 18 -- batch 0 / 504 loss: 8.188759238692e-06
batch 500 / 504 loss: 3.578609948817757e-06
Epoch 19 -- batch 0 / 504 loss: 3.5485668377077673e-06
batch 500 / 504 loss: 2.5476569135207683e-05
Epoch 20 -- batch 0 / 504 loss: 7.3410174081800506e-06
batch 500 / 504 loss: 3.481716476017027e-06
Saving checkpoint at epoch 20; prefix = chkpt-ID_160571361360402
Done Training!

==================================
Testing (cite this): dataloader for dataset DBpedia50
Testing (cite this): batch 0 / 2
Testing (cite this): batch 1 / 2
total number of ranks, torch.Size([123])
====== Ranks ======
ranks size: torch.Size([123])
test_loss: 0.12539181858301163
mr: 11120.244140625
mrr: 0.3183337152004242
h1: 0.27642276883125305
h3: 0.3414634168148041
h5: 0.35772356390953064
h10: 0.42276424169540405
==================================

Done Testing!
done with training and eval
Experiments took 1141 seconds on 
