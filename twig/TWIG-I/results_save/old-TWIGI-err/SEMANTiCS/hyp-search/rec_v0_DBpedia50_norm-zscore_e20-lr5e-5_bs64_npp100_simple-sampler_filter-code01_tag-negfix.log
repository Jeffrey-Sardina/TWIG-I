['run_exp.py', '0', 'DBpedia50', '20', '5e-5', 'zscore', '64', '64', '100', '0', '1', 'simple', '1']
Creating a new model from scratch
loading NN
done loading NN
loading dataset
DBpedia50
X_p: torch.Size([32203, 23])
X_p: torch.Size([2095, 23])
X_p: torch.Size([123, 23])
done loading dataset
loading filters
done loading filters
loading negative samplers
loading triple features from cache
done loading negative samplers
Running in hyperparameter evaluation mode
TWIG will be evaulaited on the validation set
and will not be tested each epoch on the validation set
running training and eval
TWIG_KGL_v0(
  (linear_struct_1): Linear(in_features=22, out_features=10, bias=True)
  (relu_1): ReLU()
  (dropout_1): Dropout(p=0.01, inplace=False)
  (linear_struct_2): Linear(in_features=10, out_features=10, bias=True)
  (relu_2): ReLU()
  (dropout_2): Dropout(p=0.01, inplace=False)
  (linear_final): Linear(in_features=10, out_features=1, bias=True)
  (sigmoid_final): Sigmoid()
)
REC: Training with epochs = 20
Epoch 1 -- batch 0 / 504 loss: 0.11243026703596115
batch 500 / 504 loss: 0.07634143531322479
Epoch 2 -- batch 0 / 504 loss: 0.07481040060520172
batch 500 / 504 loss: 0.05028744414448738
Epoch 3 -- batch 0 / 504 loss: 0.049363888800144196
batch 500 / 504 loss: 0.02550855092704296
Epoch 4 -- batch 0 / 504 loss: 0.023814229294657707
batch 500 / 504 loss: 0.014002985320985317
Epoch 5 -- batch 0 / 504 loss: 0.010474073700606823
batch 500 / 504 loss: 0.007348295301198959
Saving checkpoint at epoch 5; prefix = chkpt-ID_6479002693421434
Epoch 6 -- batch 0 / 504 loss: 0.0042970613576471806
batch 500 / 504 loss: 0.00395234627649188
Epoch 7 -- batch 0 / 504 loss: 0.002267399337142706
batch 500 / 504 loss: 0.0020975852385163307
Epoch 8 -- batch 0 / 504 loss: 0.0011197589337825775
batch 500 / 504 loss: 0.0013856446603313088
Epoch 9 -- batch 0 / 504 loss: 0.0005633403779938817
batch 500 / 504 loss: 0.0008125004824250937
Epoch 10 -- batch 0 / 504 loss: 0.0004796121793333441
batch 500 / 504 loss: 0.0007799858576618135
Saving checkpoint at epoch 10; prefix = chkpt-ID_6479002693421434
Epoch 11 -- batch 0 / 504 loss: 0.000286816997686401
batch 500 / 504 loss: 0.0005746876704506576
Epoch 12 -- batch 0 / 504 loss: 0.0003695193736348301
batch 500 / 504 loss: 0.00041264481842517853
Epoch 13 -- batch 0 / 504 loss: 0.0002686264051590115
batch 500 / 504 loss: 0.0003723017289303243
Epoch 14 -- batch 0 / 504 loss: 0.00024432240752503276
batch 500 / 504 loss: 0.0004020226188004017
Epoch 15 -- batch 0 / 504 loss: 0.0001586651342222467
batch 500 / 504 loss: 0.00020600788411684334
Saving checkpoint at epoch 15; prefix = chkpt-ID_6479002693421434
Epoch 16 -- batch 0 / 504 loss: 0.00014986337919253856
batch 500 / 504 loss: 0.00030345708364620805
Epoch 17 -- batch 0 / 504 loss: 0.00022305895981844515
batch 500 / 504 loss: 0.0002489280595909804
Epoch 18 -- batch 0 / 504 loss: 6.048426803317852e-05
batch 500 / 504 loss: 0.00021027422917541116
Epoch 19 -- batch 0 / 504 loss: 0.00010633535566739738
batch 500 / 504 loss: 0.0002399082004558295
Epoch 20 -- batch 0 / 504 loss: 0.00010516166366869584
batch 500 / 504 loss: 0.00021446269238367677
Saving checkpoint at epoch 20; prefix = chkpt-ID_6479002693421434
Done Training!

==================================
Testing (cite this): dataloader for dataset DBpedia50
Testing (cite this): batch 0 / 2
Testing (cite this): batch 1 / 2
total number of ranks, torch.Size([123])
====== Ranks ======
ranks size: torch.Size([123])
test_loss: 0.14194319397211075
mr: 17980.1796875
mrr: 0.15360480546951294
h1: 0.11382114142179489
h3: 0.1869918704032898
h5: 0.19512194395065308
h10: 0.21138212084770203
==================================

Done Testing!
done with training and eval
Experiments took 4794 seconds on 
