['run_exp.py', '0', 'DBpedia50', '20', '5e-5', 'zscore', '256', '64', '500', '0', '1', 'simple', '1']
Creating a new model from scratch
loading NN
done loading NN
loading dataset
DBpedia50
X_p: torch.Size([32203, 23])
X_p: torch.Size([2095, 23])
X_p: torch.Size([123, 23])
done loading dataset
loading filters
done loading filters
loading negative samplers
loading triple features from cache
done loading negative samplers
Running in hyperparameter evaluation mode
TWIG will be evaulaited on the validation set
and will not be tested each epoch on the validation set
running training and eval
TWIG_KGL_v0(
  (linear_struct_1): Linear(in_features=22, out_features=10, bias=True)
  (relu_1): ReLU()
  (dropout_1): Dropout(p=0.01, inplace=False)
  (linear_struct_2): Linear(in_features=10, out_features=10, bias=True)
  (relu_2): ReLU()
  (dropout_2): Dropout(p=0.01, inplace=False)
  (linear_final): Linear(in_features=10, out_features=1, bias=True)
  (sigmoid_final): Sigmoid()
)
REC: Training with epochs = 20
Epoch 1 -- batch 0 / 126 loss: 0.10929685086011887
Epoch 2 -- batch 0 / 126 loss: 0.10080431401729584
Epoch 3 -- batch 0 / 126 loss: 0.09066524356603622
Epoch 4 -- batch 0 / 126 loss: 0.07997719198465347
Epoch 5 -- batch 0 / 126 loss: 0.07212956249713898
Saving checkpoint at epoch 5; prefix = chkpt-ID_5729990065073208
Epoch 6 -- batch 0 / 126 loss: 0.06494933366775513
Epoch 7 -- batch 0 / 126 loss: 0.057911217212677
Epoch 8 -- batch 0 / 126 loss: 0.05092208832502365
Epoch 9 -- batch 0 / 126 loss: 0.04274406656622887
Epoch 10 -- batch 0 / 126 loss: 0.03633575886487961
Saving checkpoint at epoch 10; prefix = chkpt-ID_5729990065073208
Epoch 11 -- batch 0 / 126 loss: 0.028261704370379448
Epoch 12 -- batch 0 / 126 loss: 0.02274705283343792
Epoch 13 -- batch 0 / 126 loss: 0.01783503033220768
Epoch 14 -- batch 0 / 126 loss: 0.013828311115503311
Epoch 15 -- batch 0 / 126 loss: 0.010729261673986912
Saving checkpoint at epoch 15; prefix = chkpt-ID_5729990065073208
Epoch 16 -- batch 0 / 126 loss: 0.008537497371435165
Epoch 17 -- batch 0 / 126 loss: 0.006514647044241428
Epoch 18 -- batch 0 / 126 loss: 0.004822620656341314
Epoch 19 -- batch 0 / 126 loss: 0.003938944544643164
Epoch 20 -- batch 0 / 126 loss: 0.0031142851803451777
Saving checkpoint at epoch 20; prefix = chkpt-ID_5729990065073208
Done Training!

==================================
Testing (cite this): dataloader for dataset DBpedia50
Testing (cite this): batch 0 / 2
Testing (cite this): batch 1 / 2
total number of ranks, torch.Size([123])
====== Ranks ======
ranks size: torch.Size([123])
test_loss: 0.14288384467363358
mr: 16681.048828125
mrr: 0.12927484512329102
h1: 0.10569106042385101
h3: 0.1463414579629898
h5: 0.15447154641151428
h10: 0.15447154641151428
==================================

Done Testing!
done with training and eval
Experiments took 1383 seconds on 
