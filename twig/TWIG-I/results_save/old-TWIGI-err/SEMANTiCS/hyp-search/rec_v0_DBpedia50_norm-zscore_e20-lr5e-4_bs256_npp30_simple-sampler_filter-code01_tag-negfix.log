['run_exp.py', '0', 'DBpedia50', '20', '5e-4', 'zscore', '256', '64', '30', '0', '1', 'simple', '1']
Creating a new model from scratch
loading NN
done loading NN
loading dataset
DBpedia50
X_p: torch.Size([32203, 23])
X_p: torch.Size([2095, 23])
X_p: torch.Size([123, 23])
done loading dataset
loading filters
done loading filters
loading negative samplers
loading triple features from cache
done loading negative samplers
Running in hyperparameter evaluation mode
TWIG will be evaulaited on the validation set
and will not be tested each epoch on the validation set
running training and eval
TWIG_KGL_v0(
  (linear_struct_1): Linear(in_features=22, out_features=10, bias=True)
  (relu_1): ReLU()
  (dropout_1): Dropout(p=0.01, inplace=False)
  (linear_struct_2): Linear(in_features=10, out_features=10, bias=True)
  (relu_2): ReLU()
  (dropout_2): Dropout(p=0.01, inplace=False)
  (linear_final): Linear(in_features=10, out_features=1, bias=True)
  (sigmoid_final): Sigmoid()
)
REC: Training with epochs = 20
Epoch 1 -- batch 0 / 126 loss: 0.10935807228088379
Epoch 2 -- batch 0 / 126 loss: 0.03267650678753853
Epoch 3 -- batch 0 / 126 loss: 0.002674767514690757
Epoch 4 -- batch 0 / 126 loss: 0.0007731972145847976
Epoch 5 -- batch 0 / 126 loss: 0.00047838373575359583
Saving checkpoint at epoch 5; prefix = chkpt-ID_1902426191647314
Epoch 6 -- batch 0 / 126 loss: 0.00020071769540663809
Epoch 7 -- batch 0 / 126 loss: 0.00013420880713965744
Epoch 8 -- batch 0 / 126 loss: 0.00012853468069806695
Epoch 9 -- batch 0 / 126 loss: 7.099179492797703e-05
Epoch 10 -- batch 0 / 126 loss: 0.00014382287918124348
Saving checkpoint at epoch 10; prefix = chkpt-ID_1902426191647314
Epoch 11 -- batch 0 / 126 loss: 0.00011139424168504775
Epoch 12 -- batch 0 / 126 loss: 6.47730557830073e-05
Epoch 13 -- batch 0 / 126 loss: 7.42842530598864e-05
Epoch 14 -- batch 0 / 126 loss: 0.00010020924673881382
Epoch 15 -- batch 0 / 126 loss: 5.740777851315215e-05
Saving checkpoint at epoch 15; prefix = chkpt-ID_1902426191647314
Epoch 16 -- batch 0 / 126 loss: 0.00010713972733356059
Epoch 17 -- batch 0 / 126 loss: 6.766639853594825e-05
Epoch 18 -- batch 0 / 126 loss: 9.796247468329966e-05
Epoch 19 -- batch 0 / 126 loss: 7.185277354437858e-05
Epoch 20 -- batch 0 / 126 loss: 4.160982643952593e-05
Saving checkpoint at epoch 20; prefix = chkpt-ID_1902426191647314
Done Training!

==================================
Testing (cite this): dataloader for dataset DBpedia50
Testing (cite this): batch 0 / 2
Testing (cite this): batch 1 / 2
total number of ranks, torch.Size([123])
====== Ranks ======
ranks size: torch.Size([123])
test_loss: 0.13725857436656952
mr: 17329.0078125
mrr: 0.1674564927816391
h1: 0.13008129596710205
h3: 0.19512194395065308
h5: 0.19512194395065308
h10: 0.23577235639095306
==================================

Done Testing!
done with training and eval
Experiments took 275 seconds on 
