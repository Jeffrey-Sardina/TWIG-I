['run_exp.py', '0', 'DBpedia50', '20', '5e-5', 'zscore', '128', '64', '500', '0', '1', 'simple', '1']
Creating a new model from scratch
loading NN
done loading NN
loading dataset
DBpedia50
X_p: torch.Size([32203, 23])
X_p: torch.Size([2095, 23])
X_p: torch.Size([123, 23])
done loading dataset
loading filters
done loading filters
loading negative samplers
loading triple features from cache
done loading negative samplers
Running in hyperparameter evaluation mode
TWIG will be evaulaited on the validation set
and will not be tested each epoch on the validation set
running training and eval
TWIG_KGL_v0(
  (linear_struct_1): Linear(in_features=22, out_features=10, bias=True)
  (relu_1): ReLU()
  (dropout_1): Dropout(p=0.01, inplace=False)
  (linear_struct_2): Linear(in_features=10, out_features=10, bias=True)
  (relu_2): ReLU()
  (dropout_2): Dropout(p=0.01, inplace=False)
  (linear_final): Linear(in_features=10, out_features=1, bias=True)
  (sigmoid_final): Sigmoid()
)
REC: Training with epochs = 20
Epoch 1 -- batch 0 / 252 loss: 0.11013271659612656
Epoch 2 -- batch 0 / 252 loss: 0.0916898176074028
Epoch 3 -- batch 0 / 252 loss: 0.07317177206277847
Epoch 4 -- batch 0 / 252 loss: 0.059608083218336105
Epoch 5 -- batch 0 / 252 loss: 0.04438110440969467
Saving checkpoint at epoch 5; prefix = chkpt-ID_1194823879648556
Epoch 6 -- batch 0 / 252 loss: 0.0310769435018301
Epoch 7 -- batch 0 / 252 loss: 0.019723352044820786
Epoch 8 -- batch 0 / 252 loss: 0.01221638172864914
Epoch 9 -- batch 0 / 252 loss: 0.007466601673513651
Epoch 10 -- batch 0 / 252 loss: 0.004358059260994196
Saving checkpoint at epoch 10; prefix = chkpt-ID_1194823879648556
Epoch 11 -- batch 0 / 252 loss: 0.0035929314326494932
Epoch 12 -- batch 0 / 252 loss: 0.0018536518327891827
Epoch 13 -- batch 0 / 252 loss: 0.001286291633732617
Epoch 14 -- batch 0 / 252 loss: 0.0008977949037216604
Epoch 15 -- batch 0 / 252 loss: 0.0009045676561072469
Saving checkpoint at epoch 15; prefix = chkpt-ID_1194823879648556
Epoch 16 -- batch 0 / 252 loss: 0.0005115164094604552
Epoch 17 -- batch 0 / 252 loss: 0.0003811299102380872
Epoch 18 -- batch 0 / 252 loss: 0.0003318928647786379
Epoch 19 -- batch 0 / 252 loss: 0.0003045502526219934
Epoch 20 -- batch 0 / 252 loss: 0.00026207126211375
Saving checkpoint at epoch 20; prefix = chkpt-ID_1194823879648556
Done Training!

==================================
Testing (cite this): dataloader for dataset DBpedia50
Testing (cite this): batch 0 / 2
Testing (cite this): batch 1 / 2
total number of ranks, torch.Size([123])
====== Ranks ======
ranks size: torch.Size([123])
test_loss: 0.14134058356285095
mr: 17090.09765625
mrr: 0.1266191601753235
h1: 0.09756097197532654
h3: 0.1463414579629898
h5: 0.16260161995887756
h10: 0.1869918704032898
==================================

Done Testing!
done with training and eval
Experiments took 1974 seconds on 
