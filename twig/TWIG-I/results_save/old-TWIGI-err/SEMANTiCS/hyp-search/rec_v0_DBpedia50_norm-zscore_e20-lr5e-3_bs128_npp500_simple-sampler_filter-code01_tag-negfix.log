['run_exp.py', '0', 'DBpedia50', '20', '5e-3', 'zscore', '128', '64', '500', '0', '1', 'simple', '1']
Creating a new model from scratch
loading NN
done loading NN
loading dataset
DBpedia50
X_p: torch.Size([32203, 23])
X_p: torch.Size([2095, 23])
X_p: torch.Size([123, 23])
done loading dataset
loading filters
done loading filters
loading negative samplers
loading triple features from cache
done loading negative samplers
Running in hyperparameter evaluation mode
TWIG will be evaulaited on the validation set
and will not be tested each epoch on the validation set
running training and eval
TWIG_KGL_v0(
  (linear_struct_1): Linear(in_features=22, out_features=10, bias=True)
  (relu_1): ReLU()
  (dropout_1): Dropout(p=0.01, inplace=False)
  (linear_struct_2): Linear(in_features=10, out_features=10, bias=True)
  (relu_2): ReLU()
  (dropout_2): Dropout(p=0.01, inplace=False)
  (linear_final): Linear(in_features=10, out_features=1, bias=True)
  (sigmoid_final): Sigmoid()
)
REC: Training with epochs = 20
Epoch 1 -- batch 0 / 252 loss: 0.10992404818534851
Epoch 2 -- batch 0 / 252 loss: 6.829929770901799e-05
Epoch 3 -- batch 0 / 252 loss: 3.15674114972353e-05
Epoch 4 -- batch 0 / 252 loss: 3.341825504321605e-05
Epoch 5 -- batch 0 / 252 loss: 3.5588273021858186e-05
Saving checkpoint at epoch 5; prefix = chkpt-ID_3796935912341663
Epoch 6 -- batch 0 / 252 loss: 3.486650166451e-05
Epoch 7 -- batch 0 / 252 loss: 2.8034412025590427e-05
Epoch 8 -- batch 0 / 252 loss: 2.196543755417224e-05
Epoch 9 -- batch 0 / 252 loss: 1.176439764094539e-05
Epoch 10 -- batch 0 / 252 loss: 3.974748688051477e-05
Saving checkpoint at epoch 10; prefix = chkpt-ID_3796935912341663
Epoch 11 -- batch 0 / 252 loss: 3.4675154893193394e-05
Epoch 12 -- batch 0 / 252 loss: 1.538538526801858e-05
Epoch 13 -- batch 0 / 252 loss: 1.6876178051461466e-05
Epoch 14 -- batch 0 / 252 loss: 1.4206429113983177e-05
Epoch 15 -- batch 0 / 252 loss: 1.9249557226430625e-05
Saving checkpoint at epoch 15; prefix = chkpt-ID_3796935912341663
Epoch 16 -- batch 0 / 252 loss: 1.970712219190318e-05
Epoch 17 -- batch 0 / 252 loss: 1.2590625374286901e-05
Epoch 18 -- batch 0 / 252 loss: 6.7374598984315526e-06
Epoch 19 -- batch 0 / 252 loss: 1.0538211427046917e-05
Epoch 20 -- batch 0 / 252 loss: 8.727589374757372e-06
Saving checkpoint at epoch 20; prefix = chkpt-ID_3796935912341663
Done Training!

==================================
Testing (cite this): dataloader for dataset DBpedia50
Testing (cite this): batch 0 / 2
Testing (cite this): batch 1 / 2
total number of ranks, torch.Size([123])
====== Ranks ======
ranks size: torch.Size([123])
test_loss: 0.11069909110665321
mr: 12491.1142578125
mrr: 0.34427475929260254
h1: 0.30894309282302856
h3: 0.3739837408065796
h5: 0.39024388790130615
h10: 0.4065040647983551
==================================

Done Testing!
done with training and eval
Experiments took 1171 seconds on 
