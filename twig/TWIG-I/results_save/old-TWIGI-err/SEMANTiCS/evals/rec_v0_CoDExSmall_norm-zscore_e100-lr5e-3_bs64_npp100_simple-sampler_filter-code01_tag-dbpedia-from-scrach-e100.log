['run_exp.py', '0', 'CoDExSmall', '100', '5e-3', 'zscore', '64', '64', '100', '0', '1', 'simple', '0']
Creating a new model from scratch
loading NN
done loading NN
loading dataset
CoDExSmall
X_p: torch.Size([32888, 23])
X_p: torch.Size([1828, 23])
X_p: torch.Size([1827, 23])
done loading dataset
loading filters
done loading filters
loading negative samplers
loading triple features from cache
done loading negative samplers
running training and eval
TWIG_KGL_v0(
  (linear_struct_1): Linear(in_features=22, out_features=10, bias=True)
  (relu_1): ReLU()
  (dropout_1): Dropout(p=0.01, inplace=False)
  (linear_struct_2): Linear(in_features=10, out_features=10, bias=True)
  (relu_2): ReLU()
  (dropout_2): Dropout(p=0.01, inplace=False)
  (linear_final): Linear(in_features=10, out_features=1, bias=True)
  (sigmoid_final): Sigmoid()
)
REC: Training with epochs = 100
Epoch 1 -- batch 0 / 514 loss: 0.11170309036970139
batch 500 / 514 loss: 1.6105601389426738e-05
Epoch 2 -- batch 0 / 514 loss: 0.0007273389492183924
batch 500 / 514 loss: 4.053783050039783e-05
Epoch 3 -- batch 0 / 514 loss: 0.00014475220814347267
batch 500 / 514 loss: 1.1525035006343387e-05
Epoch 4 -- batch 0 / 514 loss: 4.142704347032122e-05
batch 500 / 514 loss: 0.0
Epoch 5 -- batch 0 / 514 loss: 6.236746412469074e-05
batch 500 / 514 loss: 9.956353096640669e-06
Saving checkpoint at epoch 5; prefix = chkpt-ID_6973099098128870
Epoch 6 -- batch 0 / 514 loss: 5.9796897403430194e-05
batch 500 / 514 loss: 0.0
Epoch 7 -- batch 0 / 514 loss: 0.00010539629874983802
batch 500 / 514 loss: 5.909598621656187e-05
Epoch 8 -- batch 0 / 514 loss: 0.00011430063022999093
batch 500 / 514 loss: 1.2079724911018275e-05
Epoch 9 -- batch 0 / 514 loss: 2.7255979148321785e-05
batch 500 / 514 loss: 2.0811083231819794e-05
Epoch 10 -- batch 0 / 514 loss: 0.00012124955537728965
batch 500 / 514 loss: 0.0
Saving checkpoint at epoch 10; prefix = chkpt-ID_6973099098128870
Epoch 11 -- batch 0 / 514 loss: 0.00010764183389255777
batch 500 / 514 loss: 0.0
Epoch 12 -- batch 0 / 514 loss: 1.743406755849719e-05
batch 500 / 514 loss: 0.0
Epoch 13 -- batch 0 / 514 loss: 7.541706963820616e-06
batch 500 / 514 loss: 0.0
Epoch 14 -- batch 0 / 514 loss: 0.0
batch 500 / 514 loss: 0.0
Epoch 15 -- batch 0 / 514 loss: 1.378512752125971e-05
batch 500 / 514 loss: 0.0
Saving checkpoint at epoch 15; prefix = chkpt-ID_6973099098128870
Epoch 16 -- batch 0 / 514 loss: 1.7618278434383683e-05
batch 500 / 514 loss: 0.0
Epoch 17 -- batch 0 / 514 loss: 2.402185600658413e-05
batch 500 / 514 loss: 0.0
Epoch 18 -- batch 0 / 514 loss: 4.7885267122182995e-05
batch 500 / 514 loss: 0.0
Epoch 19 -- batch 0 / 514 loss: 1.830464680097066e-05
batch 500 / 514 loss: 0.0
Epoch 20 -- batch 0 / 514 loss: 4.8963567678583786e-05
batch 500 / 514 loss: 0.0
Saving checkpoint at epoch 20; prefix = chkpt-ID_6973099098128870
Epoch 21 -- batch 0 / 514 loss: 9.484011388849467e-05
batch 500 / 514 loss: 0.0
Epoch 22 -- batch 0 / 514 loss: 2.2357380657922477e-05
batch 500 / 514 loss: 0.0
Epoch 23 -- batch 0 / 514 loss: 2.6096780857187696e-05
batch 500 / 514 loss: 0.0
Epoch 24 -- batch 0 / 514 loss: 6.263531759032048e-06
batch 500 / 514 loss: 0.0
Epoch 25 -- batch 0 / 514 loss: 0.00010714921518228948
batch 500 / 514 loss: 0.0
Saving checkpoint at epoch 25; prefix = chkpt-ID_6973099098128870
Epoch 26 -- batch 0 / 514 loss: 0.00014290004037320614
batch 500 / 514 loss: 1.208403682539938e-05
Epoch 27 -- batch 0 / 514 loss: 7.249473128467798e-07
batch 500 / 514 loss: 0.0
Epoch 28 -- batch 0 / 514 loss: 1.862725730461534e-05
batch 500 / 514 loss: 0.0
Epoch 29 -- batch 0 / 514 loss: 7.414300489472225e-05
batch 500 / 514 loss: 0.0
Epoch 30 -- batch 0 / 514 loss: 1.8901346265920438e-05
batch 500 / 514 loss: 6.244762289497885e-07
Saving checkpoint at epoch 30; prefix = chkpt-ID_6973099098128870
Epoch 31 -- batch 0 / 514 loss: 8.566652104491368e-05
batch 500 / 514 loss: 6.366154138959246e-06
Epoch 32 -- batch 0 / 514 loss: 3.7263682770571904e-06
batch 500 / 514 loss: 0.0
Epoch 33 -- batch 0 / 514 loss: 9.026351108332165e-06
batch 500 / 514 loss: 0.0
Epoch 34 -- batch 0 / 514 loss: 2.988218329846859e-05
batch 500 / 514 loss: 0.0
Epoch 35 -- batch 0 / 514 loss: 1.9800776499323547e-05
batch 500 / 514 loss: 0.0
Saving checkpoint at epoch 35; prefix = chkpt-ID_6973099098128870
Epoch 36 -- batch 0 / 514 loss: 0.0
batch 500 / 514 loss: 0.0
Epoch 37 -- batch 0 / 514 loss: 3.776807352551259e-05
batch 500 / 514 loss: 0.0
Epoch 38 -- batch 0 / 514 loss: 6.997796845098492e-06
batch 500 / 514 loss: 1.1675498171825893e-05
Epoch 39 -- batch 0 / 514 loss: 2.3485024939873256e-05
batch 500 / 514 loss: 0.0
Epoch 40 -- batch 0 / 514 loss: 5.787426925962791e-05
batch 500 / 514 loss: 0.0
Saving checkpoint at epoch 40; prefix = chkpt-ID_6973099098128870
Epoch 41 -- batch 0 / 514 loss: 7.085409015417099e-05
batch 500 / 514 loss: 0.0
Epoch 42 -- batch 0 / 514 loss: 0.0
batch 500 / 514 loss: 0.0
Epoch 43 -- batch 0 / 514 loss: 1.0787635801534634e-05
batch 500 / 514 loss: 0.0
Epoch 44 -- batch 0 / 514 loss: 1.1686247489706147e-05
batch 500 / 514 loss: 0.0
Epoch 45 -- batch 0 / 514 loss: 1.4219900549505837e-05
batch 500 / 514 loss: 0.0
Saving checkpoint at epoch 45; prefix = chkpt-ID_6973099098128870
Epoch 46 -- batch 0 / 514 loss: 2.571325057942886e-05
batch 500 / 514 loss: 0.0
Epoch 47 -- batch 0 / 514 loss: 4.226022429065779e-05
batch 500 / 514 loss: 0.0
Epoch 48 -- batch 0 / 514 loss: 0.0
batch 500 / 514 loss: 6.160104021546431e-06
Epoch 49 -- batch 0 / 514 loss: 4.6810793719487265e-05
batch 500 / 514 loss: 0.0
Epoch 50 -- batch 0 / 514 loss: 3.165642192470841e-05
batch 500 / 514 loss: 0.0
Saving checkpoint at epoch 50; prefix = chkpt-ID_6973099098128870
Epoch 51 -- batch 0 / 514 loss: 0.0
batch 500 / 514 loss: 0.0
Epoch 52 -- batch 0 / 514 loss: 3.977016967837699e-05
batch 500 / 514 loss: 0.0
Epoch 53 -- batch 0 / 514 loss: 4.005602386314422e-05
batch 500 / 514 loss: 0.0
Epoch 54 -- batch 0 / 514 loss: 1.6601994502707385e-05
batch 500 / 514 loss: 0.0
Epoch 55 -- batch 0 / 514 loss: 7.01819735695608e-05
batch 500 / 514 loss: 0.0
Saving checkpoint at epoch 55; prefix = chkpt-ID_6973099098128870
Epoch 56 -- batch 0 / 514 loss: 0.0
batch 500 / 514 loss: 0.0
Epoch 57 -- batch 0 / 514 loss: 0.0
batch 500 / 514 loss: 0.0
Epoch 58 -- batch 0 / 514 loss: 0.0
batch 500 / 514 loss: 1.4431845556828193e-05
Epoch 59 -- batch 0 / 514 loss: 4.2672572817537e-06
batch 500 / 514 loss: 0.0
Epoch 60 -- batch 0 / 514 loss: 0.0
batch 500 / 514 loss: 0.0
Saving checkpoint at epoch 60; prefix = chkpt-ID_6973099098128870
Epoch 61 -- batch 0 / 514 loss: 4.0171747968997806e-05
batch 500 / 514 loss: 0.0
Epoch 62 -- batch 0 / 514 loss: 9.065352787729353e-05
batch 500 / 514 loss: 0.0
Epoch 63 -- batch 0 / 514 loss: 3.0900316687620943e-06
batch 500 / 514 loss: 3.166180613334291e-05
Epoch 64 -- batch 0 / 514 loss: 5.774262535851449e-05
batch 500 / 514 loss: 1.4056364307180047e-05
Epoch 65 -- batch 0 / 514 loss: 0.0
batch 500 / 514 loss: 0.0
Saving checkpoint at epoch 65; prefix = chkpt-ID_6973099098128870
Epoch 66 -- batch 0 / 514 loss: 0.0
batch 500 / 514 loss: 0.0
Epoch 67 -- batch 0 / 514 loss: 0.0
batch 500 / 514 loss: 0.0
Epoch 68 -- batch 0 / 514 loss: 1.569735468365252e-05
batch 500 / 514 loss: 0.0
Epoch 69 -- batch 0 / 514 loss: 0.0
batch 500 / 514 loss: 0.0
Epoch 70 -- batch 0 / 514 loss: 0.0
batch 500 / 514 loss: 3.985880084655946e-06
Saving checkpoint at epoch 70; prefix = chkpt-ID_6973099098128870
Epoch 71 -- batch 0 / 514 loss: 1.1736715350707527e-05
batch 500 / 514 loss: 0.0
Epoch 72 -- batch 0 / 514 loss: 4.7128785809036344e-05
batch 500 / 514 loss: 0.0
Epoch 73 -- batch 0 / 514 loss: 2.949002373497933e-05
batch 500 / 514 loss: 0.0
Epoch 74 -- batch 0 / 514 loss: 2.4071300686046015e-06
batch 500 / 514 loss: 0.0
Epoch 75 -- batch 0 / 514 loss: 0.0
batch 500 / 514 loss: 0.0
Saving checkpoint at epoch 75; prefix = chkpt-ID_6973099098128870
Epoch 76 -- batch 0 / 514 loss: 2.032818883890286e-05
batch 500 / 514 loss: 0.0
Epoch 77 -- batch 0 / 514 loss: 0.0
batch 500 / 514 loss: 0.0
Epoch 78 -- batch 0 / 514 loss: 0.0
batch 500 / 514 loss: 0.0
Epoch 79 -- batch 0 / 514 loss: 0.0
batch 500 / 514 loss: 0.0
Epoch 80 -- batch 0 / 514 loss: 2.3025282644084655e-05
batch 500 / 514 loss: 0.0
Saving checkpoint at epoch 80; prefix = chkpt-ID_6973099098128870
Epoch 81 -- batch 0 / 514 loss: 0.0
batch 500 / 514 loss: 0.0
Epoch 82 -- batch 0 / 514 loss: 7.431215635733679e-05
batch 500 / 514 loss: 0.0
Epoch 83 -- batch 0 / 514 loss: 1.4730294424225576e-05
batch 500 / 514 loss: 0.0
Epoch 84 -- batch 0 / 514 loss: 9.727902579470538e-06
batch 500 / 514 loss: 0.0
Epoch 85 -- batch 0 / 514 loss: 3.151839962356462e-07
batch 500 / 514 loss: 0.0
Saving checkpoint at epoch 85; prefix = chkpt-ID_6973099098128870
Epoch 86 -- batch 0 / 514 loss: 4.5969449274707586e-05
batch 500 / 514 loss: 0.0
Epoch 87 -- batch 0 / 514 loss: 1.2788988897227682e-05
batch 500 / 514 loss: 0.0
Epoch 88 -- batch 0 / 514 loss: 3.3511930723761907e-06
batch 500 / 514 loss: 0.0
Epoch 89 -- batch 0 / 514 loss: 0.0
batch 500 / 514 loss: 2.341075560252648e-05
Epoch 90 -- batch 0 / 514 loss: 0.0
batch 500 / 514 loss: 1.356752181891352e-05
Saving checkpoint at epoch 90; prefix = chkpt-ID_6973099098128870
Epoch 91 -- batch 0 / 514 loss: 1.9394126866245642e-05
batch 500 / 514 loss: 0.0
Epoch 92 -- batch 0 / 514 loss: 0.0
batch 500 / 514 loss: 1.3000160834053531e-05
Epoch 93 -- batch 0 / 514 loss: 0.0
batch 500 / 514 loss: 0.0
Epoch 94 -- batch 0 / 514 loss: 8.59738156577805e-06
batch 500 / 514 loss: 3.080174792557955e-05
Epoch 95 -- batch 0 / 514 loss: 0.00012037585838697851
batch 500 / 514 loss: 0.0
Saving checkpoint at epoch 95; prefix = chkpt-ID_6973099098128870
Epoch 96 -- batch 0 / 514 loss: 8.377276390092447e-05
batch 500 / 514 loss: 0.0
Epoch 97 -- batch 0 / 514 loss: 2.4644530185469193e-06
batch 500 / 514 loss: 0.0
Epoch 98 -- batch 0 / 514 loss: 0.0
batch 500 / 514 loss: 0.0
Epoch 99 -- batch 0 / 514 loss: 0.00011348817497491837
batch 500 / 514 loss: 0.0
Epoch 100 -- batch 0 / 514 loss: 0.0
batch 500 / 514 loss: 0.0
Saving checkpoint at epoch 100; prefix = chkpt-ID_6973099098128870
Done Training!

==================================
Testing (cite this): dataloader for dataset CoDExSmall
Testing (cite this): batch 0 / 29
Testing (cite this): batch 1 / 29
Testing (cite this): batch 2 / 29
Testing (cite this): batch 3 / 29
Testing (cite this): batch 4 / 29
Testing (cite this): batch 5 / 29
Testing (cite this): batch 6 / 29
Testing (cite this): batch 7 / 29
Testing (cite this): batch 8 / 29
Testing (cite this): batch 9 / 29
Testing (cite this): batch 10 / 29
Testing (cite this): batch 11 / 29
Testing (cite this): batch 12 / 29
Testing (cite this): batch 13 / 29
Testing (cite this): batch 14 / 29
Testing (cite this): batch 15 / 29
Testing (cite this): batch 16 / 29
Testing (cite this): batch 17 / 29
Testing (cite this): batch 18 / 29
Testing (cite this): batch 19 / 29
Testing (cite this): batch 20 / 29
Testing (cite this): batch 21 / 29
Testing (cite this): batch 22 / 29
Testing (cite this): batch 23 / 29
Testing (cite this): batch 24 / 29
Testing (cite this): batch 25 / 29
Testing (cite this): batch 26 / 29
Testing (cite this): batch 27 / 29
Testing (cite this): batch 28 / 29
total number of ranks, torch.Size([1828])
====== Ranks ======
ranks size: torch.Size([1828])
test_loss: 1.6131661422550678
mr: 31.32221031188965
mrr: 0.3909994959831238
h1: 0.33424508571624756
h3: 0.35886213183403015
h5: 0.3933260440826416
h10: 0.5382932424545288
==================================

Done Testing!
done with training and eval
Experiments took 1772 seconds on 
