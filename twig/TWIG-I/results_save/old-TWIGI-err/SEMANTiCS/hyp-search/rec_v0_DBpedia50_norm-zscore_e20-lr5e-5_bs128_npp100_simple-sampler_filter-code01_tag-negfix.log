['run_exp.py', '0', 'DBpedia50', '20', '5e-5', 'zscore', '128', '64', '100', '0', '1', 'simple', '1']
Creating a new model from scratch
loading NN
done loading NN
loading dataset
DBpedia50
X_p: torch.Size([32203, 23])
X_p: torch.Size([2095, 23])
X_p: torch.Size([123, 23])
done loading dataset
loading filters
done loading filters
loading negative samplers
loading triple features from cache
done loading negative samplers
Running in hyperparameter evaluation mode
TWIG will be evaulaited on the validation set
and will not be tested each epoch on the validation set
running training and eval
TWIG_KGL_v0(
  (linear_struct_1): Linear(in_features=22, out_features=10, bias=True)
  (relu_1): ReLU()
  (dropout_1): Dropout(p=0.01, inplace=False)
  (linear_struct_2): Linear(in_features=10, out_features=10, bias=True)
  (relu_2): ReLU()
  (dropout_2): Dropout(p=0.01, inplace=False)
  (linear_final): Linear(in_features=10, out_features=1, bias=True)
  (sigmoid_final): Sigmoid()
)
REC: Training with epochs = 20
Epoch 1 -- batch 0 / 252 loss: 0.11029104143381119
Epoch 2 -- batch 0 / 252 loss: 0.09136663377285004
Epoch 3 -- batch 0 / 252 loss: 0.07250230014324188
Epoch 4 -- batch 0 / 252 loss: 0.05941620096564293
Epoch 5 -- batch 0 / 252 loss: 0.04490731284022331
Saving checkpoint at epoch 5; prefix = chkpt-ID_6007631888976936
Epoch 6 -- batch 0 / 252 loss: 0.031008247286081314
Epoch 7 -- batch 0 / 252 loss: 0.020239323377609253
Epoch 8 -- batch 0 / 252 loss: 0.012649676762521267
Epoch 9 -- batch 0 / 252 loss: 0.007413375191390514
Epoch 10 -- batch 0 / 252 loss: 0.005068222060799599
Saving checkpoint at epoch 10; prefix = chkpt-ID_6007631888976936
Epoch 11 -- batch 0 / 252 loss: 0.0028765685856342316
Epoch 12 -- batch 0 / 252 loss: 0.002010952914133668
Epoch 13 -- batch 0 / 252 loss: 0.0014055917272344232
Epoch 14 -- batch 0 / 252 loss: 0.0009856547694653273
Epoch 15 -- batch 0 / 252 loss: 0.0006821456481702626
Saving checkpoint at epoch 15; prefix = chkpt-ID_6007631888976936
Epoch 16 -- batch 0 / 252 loss: 0.0008208559011109173
Epoch 17 -- batch 0 / 252 loss: 0.0004297827836126089
Epoch 18 -- batch 0 / 252 loss: 0.00035387769457884133
Epoch 19 -- batch 0 / 252 loss: 0.0003411000070627779
Epoch 20 -- batch 0 / 252 loss: 0.0002844634873326868
Saving checkpoint at epoch 20; prefix = chkpt-ID_6007631888976936
Done Training!

==================================
Testing (cite this): dataloader for dataset DBpedia50
Testing (cite this): batch 0 / 2
Testing (cite this): batch 1 / 2
total number of ranks, torch.Size([123])
====== Ranks ======
ranks size: torch.Size([123])
test_loss: 0.14143278449773788
mr: 17091.529296875
mrr: 0.12349160760641098
h1: 0.08943089097738266
h3: 0.1463414579629898
h5: 0.16260161995887756
h10: 0.17886178195476532
==================================

Done Testing!
done with training and eval
Experiments took 398 seconds on 
