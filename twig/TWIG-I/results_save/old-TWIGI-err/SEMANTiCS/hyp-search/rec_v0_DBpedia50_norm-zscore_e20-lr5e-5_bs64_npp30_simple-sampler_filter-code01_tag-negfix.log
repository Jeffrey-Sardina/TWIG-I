['run_exp.py', '0', 'DBpedia50', '20', '5e-5', 'zscore', '64', '64', '30', '0', '1', 'simple', '1']
Creating a new model from scratch
loading NN
done loading NN
loading dataset
DBpedia50
X_p: torch.Size([32203, 23])
X_p: torch.Size([2095, 23])
X_p: torch.Size([123, 23])
done loading dataset
loading filters
done loading filters
loading negative samplers
loading triple features from cache
done loading negative samplers
Running in hyperparameter evaluation mode
TWIG will be evaulaited on the validation set
and will not be tested each epoch on the validation set
running training and eval
TWIG_KGL_v0(
  (linear_struct_1): Linear(in_features=22, out_features=10, bias=True)
  (relu_1): ReLU()
  (dropout_1): Dropout(p=0.01, inplace=False)
  (linear_struct_2): Linear(in_features=10, out_features=10, bias=True)
  (relu_2): ReLU()
  (dropout_2): Dropout(p=0.01, inplace=False)
  (linear_final): Linear(in_features=10, out_features=1, bias=True)
  (sigmoid_final): Sigmoid()
)
REC: Training with epochs = 20
Epoch 1 -- batch 0 / 504 loss: 0.1119987890124321
batch 500 / 504 loss: 0.07730843126773834
Epoch 2 -- batch 0 / 504 loss: 0.07507240027189255
batch 500 / 504 loss: 0.05036379024386406
Epoch 3 -- batch 0 / 504 loss: 0.050329722464084625
batch 500 / 504 loss: 0.02519320324063301
Epoch 4 -- batch 0 / 504 loss: 0.023928601294755936
batch 500 / 504 loss: 0.01409840676933527
Epoch 5 -- batch 0 / 504 loss: 0.010392558760941029
batch 500 / 504 loss: 0.007578324526548386
Saving checkpoint at epoch 5; prefix = chkpt-ID_5083718645353081
Epoch 6 -- batch 0 / 504 loss: 0.004324447363615036
batch 500 / 504 loss: 0.003957354463636875
Epoch 7 -- batch 0 / 504 loss: 0.00208453880622983
batch 500 / 504 loss: 0.002030168194323778
Epoch 8 -- batch 0 / 504 loss: 0.0010078959167003632
batch 500 / 504 loss: 0.0016015202272683382
Epoch 9 -- batch 0 / 504 loss: 0.0008055788930505514
batch 500 / 504 loss: 0.0006026776391081512
Epoch 10 -- batch 0 / 504 loss: 0.0002882622356992215
batch 500 / 504 loss: 0.0008607027702964842
Saving checkpoint at epoch 10; prefix = chkpt-ID_5083718645353081
Epoch 11 -- batch 0 / 504 loss: 0.00018316350178793073
batch 500 / 504 loss: 0.0005804278189316392
Epoch 12 -- batch 0 / 504 loss: 0.0004954568576067686
batch 500 / 504 loss: 0.0005295998998917639
Epoch 13 -- batch 0 / 504 loss: 0.0001788956142263487
batch 500 / 504 loss: 0.00038389794644899666
Epoch 14 -- batch 0 / 504 loss: 0.0004156758659519255
batch 500 / 504 loss: 0.00020217370183672756
Epoch 15 -- batch 0 / 504 loss: 0.00020730728283524513
batch 500 / 504 loss: 0.00028313713846728206
Saving checkpoint at epoch 15; prefix = chkpt-ID_5083718645353081
Epoch 16 -- batch 0 / 504 loss: 2.9655097023351118e-05
batch 500 / 504 loss: 0.00013846934598404914
Epoch 17 -- batch 0 / 504 loss: 0.00019836350111290812
batch 500 / 504 loss: 0.00023374121519736946
Epoch 18 -- batch 0 / 504 loss: 0.0001594291825313121
batch 500 / 504 loss: 0.0004606966977007687
Epoch 19 -- batch 0 / 504 loss: 0.00024481164291501045
batch 500 / 504 loss: 0.0005551729118451476
Epoch 20 -- batch 0 / 504 loss: 4.681468999478966e-05
batch 500 / 504 loss: 5.709981996915303e-05
Saving checkpoint at epoch 20; prefix = chkpt-ID_5083718645353081
Done Training!

==================================
Testing (cite this): dataloader for dataset DBpedia50
Testing (cite this): batch 0 / 2
Testing (cite this): batch 1 / 2
total number of ranks, torch.Size([123])
====== Ranks ======
ranks size: torch.Size([123])
test_loss: 0.14241375029087067
mr: 18047.560546875
mrr: 0.15094149112701416
h1: 0.11382114142179489
h3: 0.1869918704032898
h5: 0.19512194395065308
h10: 0.21138212084770203
==================================

Done Testing!
done with training and eval
Experiments took 301 seconds on 
