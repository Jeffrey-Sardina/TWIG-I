['run_exp.py', '0', 'DBpedia50', '20', '5e-4', 'zscore', '64', '64', '30', '0', '1', 'simple', '1']
Creating a new model from scratch
loading NN
done loading NN
loading dataset
DBpedia50
X_p: torch.Size([32203, 23])
X_p: torch.Size([2095, 23])
X_p: torch.Size([123, 23])
done loading dataset
loading filters
done loading filters
loading negative samplers
loading triple features from cache
done loading negative samplers
Running in hyperparameter evaluation mode
TWIG will be evaulaited on the validation set
and will not be tested each epoch on the validation set
running training and eval
TWIG_KGL_v0(
  (linear_struct_1): Linear(in_features=22, out_features=10, bias=True)
  (relu_1): ReLU()
  (dropout_1): Dropout(p=0.01, inplace=False)
  (linear_struct_2): Linear(in_features=10, out_features=10, bias=True)
  (relu_2): ReLU()
  (dropout_2): Dropout(p=0.01, inplace=False)
  (linear_final): Linear(in_features=10, out_features=1, bias=True)
  (sigmoid_final): Sigmoid()
)
REC: Training with epochs = 20
Epoch 1 -- batch 0 / 504 loss: 0.11121769994497299
batch 500 / 504 loss: 0.001113868085667491
Epoch 2 -- batch 0 / 504 loss: 0.0007579252705909312
batch 500 / 504 loss: 0.0003626660327427089
Epoch 3 -- batch 0 / 504 loss: 0.00013110153668094426
batch 500 / 504 loss: 0.00012097419676138088
Epoch 4 -- batch 0 / 504 loss: 5.5883465392980725e-05
batch 500 / 504 loss: 0.00013892760034650564
Epoch 5 -- batch 0 / 504 loss: 8.055644138948992e-05
batch 500 / 504 loss: 8.431024616584182e-05
Saving checkpoint at epoch 5; prefix = chkpt-ID_9711156431444572
Epoch 6 -- batch 0 / 504 loss: 1.2579688700498082e-05
batch 500 / 504 loss: 0.00015812237688805908
Epoch 7 -- batch 0 / 504 loss: 9.387615591549547e-07
batch 500 / 504 loss: 0.0001436948514310643
Epoch 8 -- batch 0 / 504 loss: 1.9070092093897983e-05
batch 500 / 504 loss: 9.948214574251324e-05
Epoch 9 -- batch 0 / 504 loss: 0.0
batch 500 / 504 loss: 0.00015009864000603557
Epoch 10 -- batch 0 / 504 loss: 0.0001264849997824058
batch 500 / 504 loss: 8.139020064845681e-05
Saving checkpoint at epoch 10; prefix = chkpt-ID_9711156431444572
Epoch 11 -- batch 0 / 504 loss: 0.0
batch 500 / 504 loss: 0.0002784531388897449
Epoch 12 -- batch 0 / 504 loss: 0.00010662473505362868
batch 500 / 504 loss: 0.0
Epoch 13 -- batch 0 / 504 loss: 1.8280004951520823e-05
batch 500 / 504 loss: 0.00019763364980462939
Epoch 14 -- batch 0 / 504 loss: 4.375538628664799e-05
batch 500 / 504 loss: 4.540012378129177e-05
Epoch 15 -- batch 0 / 504 loss: 0.0
batch 500 / 504 loss: 1.3111896805639844e-05
Saving checkpoint at epoch 15; prefix = chkpt-ID_9711156431444572
Epoch 16 -- batch 0 / 504 loss: 0.0
batch 500 / 504 loss: 5.855883864569478e-05
Epoch 17 -- batch 0 / 504 loss: 9.960874012904242e-05
batch 500 / 504 loss: 0.0001053091837093234
Epoch 18 -- batch 0 / 504 loss: 1.9142145902151242e-05
batch 500 / 504 loss: 0.00013626691361423582
Epoch 19 -- batch 0 / 504 loss: 0.0
batch 500 / 504 loss: 4.27073537139222e-05
Epoch 20 -- batch 0 / 504 loss: 0.0
batch 500 / 504 loss: 5.063609205535613e-05
Saving checkpoint at epoch 20; prefix = chkpt-ID_9711156431444572
Done Training!

==================================
Testing (cite this): dataloader for dataset DBpedia50
Testing (cite this): batch 0 / 2
Testing (cite this): batch 1 / 2
total number of ranks, torch.Size([123])
====== Ranks ======
ranks size: torch.Size([123])
test_loss: 0.11264915391802788
mr: 13148.841796875
mrr: 0.22944322228431702
h1: 0.15447154641151428
h3: 0.2926829159259796
h5: 0.3252032399177551
h10: 0.34959349036216736
==================================

Done Testing!
done with training and eval
Experiments took 292 seconds on 
